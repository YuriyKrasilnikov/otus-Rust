[package]
name = "openchat"
version = "0.1.0"
edition = "2021"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
accelerate-src = { version = "0.3.1", optional = true }
candle-flash-attn = { version = "0.3.1", optional = true }
candle-onnx = { version = "0.3.1", optional = true }
cudarc = { version = "0.9.15", optional = true }
half = { version = "2.3.1", optional = true }
intel-mkl-src = { version = "0.8.1", optional = true }
pyo3 = { version = "0.20.0", features = ["auto-initialize"], optional = true }

anyhow = "1.0.75"
candle-core = "0.3.1"
candle-nn = "0.3.1"
candle-transformers = "0.3.1"
clap = { version = "4.4.10", features = ["derive"] }
criterion = "0.5.1"
env_logger = "0.10.1"
hf-hub = "0.3.2"
log = "0.4.20"
serde = { version = "1.0.193", features = ["derive"] }
serde_json = "1.0.108"
tokenizers = "0.15.0"
tracing = "0.1.40"
tracing-chrome = "0.7.1"
tracing-subscriber = { version = "0.3.18", features = ["env-filter"] }
lru = "0.12.1"

[features]
default = []
accelerate = ["dep:accelerate-src", "candle-core/accelerate", "candle-nn/accelerate", "candle-transformers/accelerate"]
cuda = ["candle-core/cuda", "candle-nn/cuda", "candle-transformers/cuda"]
cudnn = ["candle-core/cudnn"]
flash-attn = ["cuda", "candle-transformers/flash-attn", "dep:candle-flash-attn"]
mkl = ["dep:intel-mkl-src", "candle-core/mkl", "candle-nn/mkl", "candle-transformers/mkl"]
nccl = ["cuda", "cudarc/nccl", "dep:half"]
onnx = ["candle-onnx"]
